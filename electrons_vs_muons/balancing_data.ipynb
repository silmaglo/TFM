{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing data between e, mu, and noise\n",
    "\n",
    "we will use this [url](https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/73/36a13185c2acff44d601dc6107b5347e075561a49e15ddd4e69988414c3e/imbalanced_learn-0.6.2-py3-none-any.whl (163kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 790kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /gpfs/users/lopezs/anaconda3/lib/python3.7/site-packages (from imbalanced-learn) (0.13.2)\n",
      "Requirement already satisfied: scipy>=0.17 in /gpfs/users/lopezs/anaconda3/lib/python3.7/site-packages (from imbalanced-learn) (1.4.1)\n",
      "Collecting scikit-learn>=0.22 (from imbalanced-learn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/b6/126263db075fbcc79107749f906ec1c7639f69d2d017807c6574792e517e/scikit_learn-0.22.2.post1-cp37-cp37m-manylinux1_x86_64.whl (7.1MB)\n",
      "\u001b[K     |████████████████████████████████| 7.1MB 13.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11 in /gpfs/users/lopezs/anaconda3/lib/python3.7/site-packages (from imbalanced-learn) (1.17.2)\n",
      "Installing collected packages: scikit-learn, imbalanced-learn\n",
      "  Found existing installation: scikit-learn 0.21.3\n",
      "    Uninstalling scikit-learn-0.21.3:\n",
      "      Successfully uninstalled scikit-learn-0.21.3\n",
      "Successfully installed imbalanced-learn-0.6.2 scikit-learn-0.22.2.post1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6.2\n"
     ]
    }
   ],
   "source": [
    "# check version number\n",
    "import imblearn\n",
    "print(imblearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random oversampling** can be implemented using the `RandomOverSampler` class.\n",
    "\n",
    "The class can be defined and takes a sampling_strategy argument that can be set to “minority” to automatically balance the minority class with majority class or classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 9900, 1: 100})\n",
      "Counter({0: 9900, 1: 9900})\n"
     ]
    }
   ],
   "source": [
    "# example of random oversampling to balance the class distribution\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=10000, weights=[0.99], flip_y=0)\n",
    "# summarize class distribution\n",
    "print(Counter(y))\n",
    "\n",
    "# define oversampling strategy\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "#This means that if the majority class had 1,000 examples and the minority class had \n",
    "#100, this strategy would oversampling the minority class so that it has 1,000 examples.\n",
    "\n",
    "# fit and apply the transform\n",
    "X_over, y_over = oversample.fit_resample(X, y)\n",
    "# summarize class distribution\n",
    "print(Counter(y_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I had 9900 sample for class 0 and just 100 for class 1, and then 9800 samples for the 1 class have been added. Let's try with our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = np.load('/gpfs/projects/damic/eVSmuVSn_1.npz')\n",
    "X = loaded['data']\n",
    "y = loaded['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to apply just the oversample to the train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2560, 1: 1981, 2: 602})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_X = X_train.reshape((X_train.shape[0], X_train.shape[1]* X_train.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2560, 2: 2560, 1: 1981})\n"
     ]
    }
   ],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "# fit and apply the transform\n",
    "X_over, y_over = oversample.fit_resample(aux_X, y_train)\n",
    "# summarize class distribution\n",
    "print(Counter(y_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat one more time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 2560, 0: 2560, 2: 2560})\n"
     ]
    }
   ],
   "source": [
    "# fit and apply the transform\n",
    "X_over_f, y_over_f = oversample.fit_resample(X_over, y_over)\n",
    "# summarize class distribution\n",
    "print(Counter(y_over_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7680, 84656)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_over_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5143, 296, 286)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redefining again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_over_f.reshape((X_over_f.shape[0], X_train.shape[1], X_train.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7680, 296, 286)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we observe, we have increased the number of samples from aprox 5000 to more than 7500 for the trainning. Observing that the muon data has been increased from 600 to 2560, this issue can lead to overfitting. So we will take a new approach:\n",
    "* Downsample the noise data\n",
    "* Oversample the muon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5143, 84656)\n"
     ]
    }
   ],
   "source": [
    "print(aux_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2560, 1: 1981, 2: 602})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 1981, 1: 1981, 2: 602})\n"
     ]
    }
   ],
   "source": [
    "#undersample the noise to aprox the sample of electrons\n",
    "\n",
    "under = RandomUnderSampler(sampling_strategy={0: 1981} )\n",
    "\n",
    "X_under, y_under = under.fit_resample(aux_X, y_train)\n",
    "\n",
    "print(Counter(y_under))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 1981, 1: 1981, 2: 1981})\n"
     ]
    }
   ],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "X_over, y_over = oversample.fit_resample(X_under, y_under)\n",
    "\n",
    "print(Counter(y_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5943, 84656), (5943,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_over.shape, y_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5143, 296, 286), (5143,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_over.reshape((X_over.shape[0], X_train.shape[1], X_train.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5943, 296, 286)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the same amount of sample of each class! Now we save these arrays (for training and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('/gpfs/projects/damic/eVSmuVSn_tr1', data=X_train, labels=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('/gpfs/projects/damic/eVSmuVSn_te1', data_test=X_test, labels_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

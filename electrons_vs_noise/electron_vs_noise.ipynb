{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a model to differentiate between noise and electrons from scratch\n",
    "\n",
    "In this notebook, we will build a convolutional neural network to classify a signal as electron or noise. Therefore, we are facing a binary classification problem: electron or noise. This is the reason why we will have just one neuron in the output layer with sigmoidal activation.\n",
    "\n",
    "First we import the data stored in a file called `eVSn.npz` composed of two variables: 'data' for the numpy arrays with energy or noise, and 'labels' where 1 stands for electron signal and 0 for noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = np.load('/Users/Silvia/Desktop/TFM/e_VS_n/eVSn.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = loaded['data']\n",
    "y = loaded['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is loaded, we split it into train and test partitions with sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3942, 201, 147)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3942, 201, 147, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our network will be composed of a stack of alternate layers of `Conv2D` (with `relu` activation) and `MaxPooling2D` layers. It is important to note that the depth of feature maps progressively increases as we move through the neural network (from 32 to 128) while the size of feature maps decreases (from 200x146 to 70x7).\n",
    "\n",
    "As we are attacking a binary classification problem (electron or noise), we are going to finish the network with a single unit (a dense layer of size 1) and with a sigmoid activation. This unit will encode the probability that our network is looking at one class or another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_y, window_x = 201,147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 200, 146, 32)      160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 100, 73, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 98, 71, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 49, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 47, 33, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 23, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 21, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 10, 7, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8960)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2050)              18370050  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               1050112   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 19,660,771\n",
      "Trainable params: 19,660,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(2,2), activation='relu', input_shape=(window_y, window_x, 1)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128,(3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128,(3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(units= 2050, activation='softmax'))\n",
    "model.add(layers.Dense(units= 512, activation='softmax'))\n",
    "model.add(layers.Dense(units= 1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compile, we will use the `RMSprop`(lr=1e-4) omptimizer. As we are facing the binary classification problem, we will use binary crossentropy as our loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.RMSprop(lr= 1e-4),loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make the fit, where the input will be composed of X_train with the numpy arrays with energy of noise and y_train with the labels for noise or energy. We are going to run 30 epochs and use a validation split of 0.2 of the total training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3153 samples, validate on 789 samples\n",
      "Epoch 1/30\n",
      "3153/3153 [==============================] - 81s 26ms/step - loss: 0.6931 - acc: 0.6131 - val_loss: 0.6930 - val_acc: 0.9759\n",
      "Epoch 2/30\n",
      "3153/3153 [==============================] - 80s 25ms/step - loss: 0.6929 - acc: 0.8195 - val_loss: 0.6928 - val_acc: 0.4968\n",
      "Epoch 3/30\n",
      "3153/3153 [==============================] - 80s 25ms/step - loss: 0.6927 - acc: 0.5046 - val_loss: 0.6926 - val_acc: 0.4968\n",
      "Epoch 4/30\n",
      "3153/3153 [==============================] - 80s 25ms/step - loss: 0.6925 - acc: 0.5046 - val_loss: 0.6924 - val_acc: 0.4968\n",
      "Epoch 5/30\n",
      "3153/3153 [==============================] - 80s 25ms/step - loss: 0.6922 - acc: 0.5046 - val_loss: 0.6921 - val_acc: 0.4968\n",
      "Epoch 6/30\n",
      "3153/3153 [==============================] - 80s 25ms/step - loss: 0.6919 - acc: 0.5046 - val_loss: 0.6918 - val_acc: 0.4968\n",
      "Epoch 7/30\n",
      "3153/3153 [==============================] - 81s 26ms/step - loss: 0.6915 - acc: 0.5046 - val_loss: 0.6914 - val_acc: 0.4968\n",
      "Epoch 8/30\n",
      "3153/3153 [==============================] - 80s 25ms/step - loss: 0.6912 - acc: 0.5046 - val_loss: 0.6911 - val_acc: 0.4968\n",
      "Epoch 9/30\n",
      "3153/3153 [==============================] - 79s 25ms/step - loss: 0.6907 - acc: 0.5046 - val_loss: 0.6907 - val_acc: 0.4968\n",
      "Epoch 10/30\n",
      "3153/3153 [==============================] - 79s 25ms/step - loss: 0.6903 - acc: 0.5046 - val_loss: 0.6902 - val_acc: 0.4968\n",
      "Epoch 11/30\n",
      "3153/3153 [==============================] - 81s 26ms/step - loss: 0.6897 - acc: 0.6746 - val_loss: 0.6897 - val_acc: 0.4968\n",
      "Epoch 12/30\n",
      "3153/3153 [==============================] - 83s 26ms/step - loss: 0.6892 - acc: 0.7802 - val_loss: 0.6891 - val_acc: 0.4968\n",
      "Epoch 13/30\n",
      "3153/3153 [==============================] - 81s 26ms/step - loss: 0.6886 - acc: 0.8145 - val_loss: 0.6885 - val_acc: 0.9607\n",
      "Epoch 14/30\n",
      "3153/3153 [==============================] - 81s 26ms/step - loss: 0.6879 - acc: 0.9153 - val_loss: 0.6878 - val_acc: 0.9594\n",
      "Epoch 15/30\n",
      "3153/3153 [==============================] - 82s 26ms/step - loss: 0.6871 - acc: 0.9791 - val_loss: 0.6870 - val_acc: 0.9620\n",
      "Epoch 16/30\n",
      "3153/3153 [==============================] - 86s 27ms/step - loss: 0.6863 - acc: 0.9816 - val_loss: 0.6862 - val_acc: 0.9607\n",
      "Epoch 17/30\n",
      "3153/3153 [==============================] - 84s 27ms/step - loss: 0.6854 - acc: 0.9800 - val_loss: 0.6852 - val_acc: 0.9670\n",
      "Epoch 18/30\n",
      "3153/3153 [==============================] - 86s 27ms/step - loss: 0.6844 - acc: 0.9813 - val_loss: 0.6843 - val_acc: 0.9658\n",
      "Epoch 19/30\n",
      "3153/3153 [==============================] - 84s 27ms/step - loss: 0.6834 - acc: 0.9822 - val_loss: 0.6831 - val_acc: 0.9721\n",
      "Epoch 20/30\n",
      "3153/3153 [==============================] - 82s 26ms/step - loss: 0.6822 - acc: 0.9822 - val_loss: 0.6820 - val_acc: 0.9696\n",
      "Epoch 21/30\n",
      "3153/3153 [==============================] - 81s 26ms/step - loss: 0.6810 - acc: 0.9838 - val_loss: 0.6808 - val_acc: 0.9708\n",
      "Epoch 22/30\n",
      "3153/3153 [==============================] - 82s 26ms/step - loss: 0.6797 - acc: 0.9826 - val_loss: 0.6794 - val_acc: 0.9759\n",
      "Epoch 23/30\n",
      "3153/3153 [==============================] - 81s 26ms/step - loss: 0.6783 - acc: 0.9857 - val_loss: 0.6780 - val_acc: 0.9772\n",
      "Epoch 24/30\n",
      "3153/3153 [==============================] - 81s 26ms/step - loss: 0.6770 - acc: 0.9841 - val_loss: 0.6766 - val_acc: 0.9759\n",
      "Epoch 25/30\n",
      "3153/3153 [==============================] - 81s 26ms/step - loss: 0.6755 - acc: 0.9826 - val_loss: 0.6753 - val_acc: 0.9721\n",
      "Epoch 26/30\n",
      "3153/3153 [==============================] - 81s 26ms/step - loss: 0.6741 - acc: 0.9797 - val_loss: 0.6742 - val_acc: 0.9607\n",
      "Epoch 27/30\n",
      "3153/3153 [==============================] - 81s 26ms/step - loss: 0.6726 - acc: 0.9778 - val_loss: 0.6726 - val_acc: 0.9607\n",
      "Epoch 28/30\n",
      "3153/3153 [==============================] - 81s 26ms/step - loss: 0.6709 - acc: 0.9772 - val_loss: 0.6709 - val_acc: 0.9607\n",
      "Epoch 29/30\n",
      "3153/3153 [==============================] - 82s 26ms/step - loss: 0.6691 - acc: 0.9765 - val_loss: 0.6691 - val_acc: 0.9607\n",
      "Epoch 30/30\n",
      "3153/3153 [==============================] - 81s 26ms/step - loss: 0.6673 - acc: 0.9756 - val_loss: 0.6673 - val_acc: 0.9607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e1860690>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs= 30, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the model just trainned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_electron_or_noise_v1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we evaluate our model using the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1314, 201, 147, 1)\n"
     ]
    }
   ],
   "source": [
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1314/1314 [==============================] - 9s 7ms/step\n",
      "Accuracy with the model: 97.18%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print('Accuracy with the model: {:5.2f}%'.format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we plot some results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x576 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 5  # number of images to display\n",
    "y_pred=0\n",
    "plt.figure(figsize=(40, 8))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(1, n, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(window_y, window_x), cmap='Reds')\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if y_predicted[i]>0.5:\n",
    "        y_pred = 1\n",
    "    else:\n",
    "        y_pred = 0\n",
    "    \n",
    "    ax.set_title('Prediction: {}, Reality: {}'.format(y_pred, y_test[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
